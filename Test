Proposed GitHub repo and all architecture markdowns below.

1. Repository layout
ai-news-rag-agent/
├── README.md
├── pyproject.toml           # or requirements.txt
├── .env.example
├── src/
│   └── news_rag/
│       ├── __init__.py
│       ├── config.py
│       ├── models/
│       │   ├── news.py      # Pydantic models for articles, summaries
│       │   └── state.py     # LangGraph state definition
│       ├── tools/
│       │   ├── tavily_tool.py
│       │   ├── gnews_tool.py
│       │   └── cache.py
│       ├── core/
│       │   ├── router.py            # News vs general-knowledge routing
│       │   ├── retrieval.py         # Router-Retriever layer
│       │   ├── summarization.py     # Summarization chain
│       │   ├── verification.py      # Optional critic / verification loop
│       │   ├── graph.py             # LangGraph StateGraph wiring
│       │   └── prompts.py
│       ├── api/
│       │   └── server.py    # FastAPI wrapper exposing the agent
│       └── ui/
│           ├── streamlit_app.py     # Simple full-stack UI
│           └── components.py
├── tests/
│   ├── unit/
│   │   ├── test_tavily_tool.py
│   │   ├── test_router.py
│   │   ├── test_summarization.py
│   │   └── test_verification.py
│   └── integration/
│       ├── test_end_to_end.py
│       └── test_api.py
├── docs/
│   ├── architecture/
│   │   ├── 01_system-overview.md
│   │   ├── 02_backend-agent-architecture.md
│   │   ├── 03_retrieval-and-data-sources.md
│   │   ├── 04_generation-and-prompting.md
│   │   ├── 05_frontend-and-api.md
│   │   ├── 06_devops-and-observability.md
│   │   ├── 07_testing-and-evaluation.md
│   │   └── 08_future-work-and-extensions.md
│   ├── usage/
│   │   ├── quickstart.md
│   │   └── examples.md
│   └── api/
│       └── openapi.md
└── docker/
    ├── Dockerfile
    └── docker-compose.yml

Architecture markdown contents next.

docs/architecture/01_system-overview.md
# AI-Powered News Summarizer with Source Attribution – System Overview

## 1. Goal

RAG agent that:
- Accepts a topical query about current events.
- Fetches the most recent news from the open web.
- Produces a concise, multi-source summary.
- Attaches explicit source citations to every factual claim.
- Optionally runs a verification loop to minimize hallucinations.

Educational focus:
- Agentic RAG (Thought → Action → Observation loop).
- Real-time, ephemeral data ingestion instead of static corpora.
- Hallucination mitigation through strict source grounding. :contentReference[oaicite:0]{index=0}

## 2. High-level architecture

Logical layers:

1. **Input Router**
   - Classifies user input into:
     - `news_query` (time-sensitive, needs fresh data).
     - `general_knowledge` (can be answered with model parametric knowledge or a separate knowledge base).
   - For this project, we optimize for `news_query`.

2. **Retrieval Layer (Router–Retriever)**
   - Uses Tavily as primary search tool to fetch:
     - Titles
     - URLs
     - Cleaned article content (or extended snippets).
   - Deduplicates and filters articles.
   - Fallback to GNews or similar if Tavily credits exhausted. :contentReference[oaicite:1]{index=1}

3. **Synthesis Layer (Summarizer)**
   - LLM-based summarization over the retrieved article set.
   - Ensures every factual statement is followed by one or more citations.
   - Handles conflicting information across sources.

4. **Optional Verification Layer (Critic Agent)**
   - Reads the draft summary.
   - Checks whether each claim is supported by provided article texts and citations.
   - Requests regeneration if unsupported claims are detected. :contentReference[oaicite:2]{index=2}

5. **Agentic Control (LangGraph)**
   - Encapsulates the loop:
     - Determine query → Search → Grade relevance → Re-search if needed → Summarize → (Optionally verify).
   - Moves beyond linear chains to a stateful agent graph. :contentReference[oaicite:3]{index=3}

6. **Interface Layer**
   - Streamlit UI (for class/demo) or API + web frontend.
   - Displays:
     - User query.
     - Final summary.
     - Structured source list with expandable article excerpts.

## 3. Technology stack

**Language**
- Python 3.11+

**Core libraries**
- LangChain: base abstractions, prompts, tools, chains.
- LangGraph: agent graph and state machine.
- HTTP client: `httpx` or `requests` for Tavily/GNews.
- Pydantic: schema validation for requests/responses.
- Streamlit: simple UI.
- FastAPI: HTTP API for the agent core.

**LLM providers**
- OpenAI (e.g., GPT-4 family) for main agent.
- Optional: Ollama + local models (Llama 3/Mistral) for cost-free local dev. :contentReference[oaicite:4]{index=4}

**Storage**
- Ephemeral retrieval by default (no long-term vector store needed).
- Optional:
  - Local cache (SQLite/JSON) for recent queries.
  - In-memory store for debugging.

**Observability**
- Logging via `structlog` or stdlib logging.
- Optional: LangSmith traces for agent thought/action logs. :contentReference[oaicite:5]{index=5}

## 4. Runtime flow

1. User enters query in UI.
2. Router decides this is a `news_query`.
3. Agent executes `Search` node:
   - Calls Tavily with query.
   - Receives list of candidate articles.
4. Agent executes `Grade` node:
   - LLM evaluates relevance/coverage.
   - Optionally refines the query and loops back to `Search`.
5. Agent executes `Write` node:
   - LLM summarizes articles.
   - Attaches citations per sentence.
   - Produces structured output: `summary`, `sources`, `metadata`.
6. Optional `Verify` node:
   - LLM critic checks support for claims against article texts.
   - If issues found: request revised summary.
7. API/UI returns:
   - Final summary.
   - Ordered, deduplicated source list.
   - Debug metadata (e.g., number of search calls).

## 5. Constraints and trade-offs

- **Ephemeral, real-time data**
  - No stable ground-truth corpus; correctness is time-dependent.
- **Free-tier API limits**
  - Tavily credits are limited; must handle fallback and caching. :contentReference[oaicite:6]{index=6}
- **Context window management**
  - News articles are long; must chunk and rank content.
- **Hallucination risk**
  - Mitigated by:
    - Aggressive grounding.
    - Verification agent.
    - Citation requirements.

## 6. Sprint alignment (14 days)

- Days 1–3: Tool setup, Tavily integration, `fetch_news`.
- Days 4–7: Simple summarization chain (no agent).
- Days 8–11: LangGraph agentification with search–grade–write loop.
- Days 12–14: Streamlit UI + polish. :contentReference[oaicite:7]{index=7}


docs/architecture/02_backend-agent-architecture.md
# Backend + Agent Architecture

## 1. Responsibilities

- Provide a clean programmatic API over the news agent.
- Encapsulate:
  - Routing logic (news vs general).
  - Agent graph orchestration.
  - Tools (Tavily, GNews).
  - Config and secrets management.
- Serve both UI and external API clients.

## 2. Module breakdown

```text
src/news_rag/
  config.py
  models/
    news.py
    state.py
  tools/
    tavily_tool.py
    gnews_tool.py
    cache.py
  core/
    router.py
    retrieval.py
    summarization.py
    verification.py
    graph.py
    prompts.py
  api/
    server.py

2.1 config.py


Loads environment variables:


OPENAI_API_KEY or local LLM config.


TAVILY_API_KEY.


Optional GNEWS_API_KEY.




Holds:


Default model names.


Maximum number of articles.


Chunk sizes and overlap.


Time filters (e.g., last 24h, last 7d).




2.2 models/news.py
Key Pydantic models:


Article:


id: str


title: str


url: str


source: str


published_at: datetime | None


content: str (cleaned body or extended snippet)


score: float | None (relevance).




SummarySentence:


text: str


source_ids: list[str] (references to Article.id).




NewsSummary:


topic: str


summary_text: str


sentences: list[SummarySentence]


sources: list[Article]


meta: dict (e.g., search stats).




2.3 models/state.py
LangGraph state:
class NewsState(BaseModel):
    query: str
    query_type: Literal["news", "general"]
    articles: list[Article] = []
    summary: Optional[NewsSummary] = None
    search_attempts: int = 0
    max_search_attempts: int = 3
    status: Literal["init", "searching", "summarizing", "verifying", "done", "failed"]
    error: Optional[str] = None

3. Agent graph (LangGraph)
3.1 Nodes


route_query


Input: query: str.


Output:


query_type.




Logic: simple heuristic or LLM classifier:


If time-related phrases (“latest”, “today”, dates, etc.) → news.






search_news


Uses tavily_tool by default.


Increments search_attempts.


Adds articles to state.


Moves status to "searching".




grade_results


LLM evaluates:


Topical relevance.


Coverage (enough distinct sources?).




Actions:


If insufficient and attempts < max: refine query, loop back to search_news.


Else: proceed to summarize.






summarize_news


Uses summarization chain.


Produces NewsSummary.


Moves status to "summarizing" or "done" if verification disabled.




verify_summary (optional)


Critic agent.


Evaluates:


Are all claims grounded?


Are citations present and consistent?




If issues:


Returns feedback to summarize_news for revision.




Else: status = "done".




handle_error


Terminal node for errors.


Sets status = "failed" and populates error.




3.2 Edges


route_query → search_news (if query_type = news).


search_news → grade_results.


grade_results:


→ search_news (refined query, while attempts < max_search_attempts).


→ summarize_news (if results OK or attempts exhausted).




summarize_news:


→ verify_summary (if verification enabled).


→ terminal (if verification disabled).




verify_summary:


→ summarize_news (if major issues).


→ terminal (if accepted).




4. FastAPI layer
src/news_rag/api/server.py:


/health – basic health check.


/summarize – main entrypoint.


Request body:
{
  "query": "string",
  "verification": true,
  "max_articles": 10
}



Response body: serialized NewsSummary.




/debug/run-graph – returns trace information for debugging during dev.


The FastAPI layer:


Instantiates the LangGraph app.


Translates HTTP requests into NewsState.


Executes the graph with bounded steps.


Returns final state.


5. Concurrency and scaling


For a class project:


Single-process uvicorn with a modest worker count is sufficient.




For higher load:


Gunicorn + multiple uvicorn workers.


Shared model clients across requests (connection pooling).




Rate limiting:


Basic per-IP or per-API-key to stay within Tavily quotas.




6. Error handling strategy


Tool call failures:


Wrap Tavily/GNews calls with retries and exponential backoff.




LLM errors:


Handle provider exceptions, timeouts, and fallback models.




Agent safeguards:


Max search attempts.


Max graph steps to avoid infinite loops. 





---

### docs/architecture/03_retrieval-and-data-sources.md

```markdown
# Retrieval and Data Source Architecture

## 1. Data sources

1. **Primary: Tavily Search API**
   - Returns cleaned, parsed content optimized for LLMs.
   - Eliminates need for custom scraping.
   - Provides:
     - `title`
     - `url`
     - `content`
     - `published_at` (if available).
   - Critical advantage: direct access to article bodies or long snippets suitable for summarization. :contentReference[oaicite:9]{index=9}

2. **Fallback: GNews**
   - Used when Tavily credits are exhausted.
   - Returns:
     - `title`
     - `description`
     - `url`
     - Some content, but usually shorter than Tavily.
   - Requires optional HTML fetch + parser if deeper content needed. :contentReference[oaicite:10]{index=10}

3. **Optional: Internal cache**
   - Recent queries + results.
   - Local SQLite or JSON file.
   - Avoids repeated external calls for the same topic in short window.

## 2. Retrieval tools

### 2.1 Tavily tool (`tavily_tool.py`)

Responsibilities:
- Construct Tavily search request:
  - Query string.
  - Filters (time range, language, max results).
- Parse Tavily response into `Article` models.
- Deduplicate by URL and title.
- Enforce maximum articles per query.

Example (pseudo-interface):

```python
def fetch_news_tavily(topic: str, max_results: int = 10) -> list[Article]:
    ...

2.2 GNews tool (gnews_tool.py)
Responsibilities:


Construct GNews query (fallback only).


Optionally fetch full article HTML if description too short.


Run content cleaner to remove boilerplate (navbars, ads).


2.3 Cache layer (cache.py)
Pattern:


Key: normalized query + time window.


Value: serialized list of Article.


Strategy:


Short TTL (e.g., 15–60 minutes) to keep news reasonably fresh.


Cache hits bypass external API calls.




3. Retrieval strategy
3.1 Query formulation
Given user query q:


Use LLM or deterministic heuristics to:


Normalize query (remove filler).


Optionally expand with synonyms or related keywords.




Example:


User: "Latest developments in solid-state batteries"


Search query: "solid-state batteries latest developments 2025".




3.2 Time constraints


Default:


Limit to articles from last N days (e.g., 1–7 days).




Allow overrides via parameters:


time_range: "24h" | "7d" | "30d" | "all".




3.3 Relevance filtering and deduplication
After retrieving raw results:


Filter:


Drop:


Non-news pages (forums, product pages) where possible.


Articles without meaningful content.






Deduplicate:


Use URL equality and fuzzy title matching.


Keep higher-scoring or more recent version.




Optional: LLM-based re-ranking if needed.
4. RAG triad: retrieval specifics
4.1 Dense vs sparse retrieval
For this project:


Rely on Tavily’s own ranking as primary “retriever.”


Optional:


Build local vector index of article chunks for improved within-set retrieval.


Embeddings: small open-source model or provider embeddings.


Vector store: in-memory or ChromaDB for article chunks. 






4.2 Chunking strategy
Problem:


Articles may be long; cannot dump full text from many articles into a single prompt.


Approach:


Chunk each article into ~800–1200 token segments with overlap (e.g., 150 tokens).


Maintain metadata:


article_id


chunk_index


source


url




Use chunk-level relevance scoring when selecting context for summarization.
4.3 Ranking
Two tiers:


Article tier:


Based on:


Tavily/GNews score.


Recency.


Source diversity (avoid all from same outlet).






Chunk tier:


For top K articles (e.g., 5–8):


Rank chunks by similarity to the query using embeddings.


Select top M chunks overall (e.g., 20) as context input.






5. Failure modes and mitigations


No results


Return explicit message: “No relevant news found in selected time window.”


Optionally widen time window and retry once.




Low-quality content


For GNews fallback:


If HTML cleaner fails or content empty:


Drop article.


If too many drops, widen search terms.








Rate limits / quota exceeded


Catch specific error codes.


Switch to:


Cache results if stored.


GNews fallback.


Or degrade gracefully with partial results.






6. Ephemeral data implications


The same query may yield different results over time.


Testing:


Use recorded fixtures of Tavily/GNews responses for deterministic unit tests.




Reproducibility:


Allow optional “snapshot mode” where retrieval uses stored JSON instead of live calls for experiments and grading. 





---

### docs/architecture/04_generation-and-prompting.md

```markdown
# Generation and Prompting Architecture

## 1. Objectives

- Summarize multiple news sources into a cohesive narrative.
- Preserve factual accuracy.
- Explicitly attribute each claim to its sources.
- Handle conflicts between sources.

## 2. Summarization chain design

### 2.1 Inputs

- User query (`topic`).
- Selected article chunks (content + metadata).
- Agent metadata:
  - Number of search attempts.
  - Retrieval parameters (time range, max articles).

### 2.2 Outputs

- `NewsSummary` model:
  - Overall summary text.
  - Sentence-level breakdown with citations.
  - Normalized source list.

## 3. Prompt engineering

### 3.1 System prompt (summarizer)

Key constraints, distilled:

- You are a news summarization agent.
- Use only provided sources; do not invent new facts.
- Every factual claim must be followed by source IDs like `[1]`, `[2,3]`.
- If sources conflict, explicitly say so.
- If topics are under-specified or coverage is thin, say that clearly. :contentReference[oaicite:13]{index=13}

Prompt skeleton:

```text
You are an AI news summarizer. You receive:

- A topic.
- A list of news article excerpts, each with an ID, title, source, URL, and text content.

Your tasks:

1. Write a concise summary (3–7 bullet points) of the most important facts about the topic.
2. After every factual claim, include square-bracket citations that reference one or more article IDs,
   e.g., "The central bank raised interest rates by 0.25 percentage points.[1,3]"
3. If different sources disagree, describe the disagreement explicitly and cite both sides.
4. Do not speculate beyond what the sources say.
5. If the sources don't provide enough information to answer part of the request, state this explicitly.

Output format (JSON):

{
  "summary_text": "<full multi-paragraph summary>",
  "sentences": [
    {
      "text": "...",
      "source_ids": ["1", "3"]
    }
  ]
}

3.2 System prompt (critic / verification agent)
Responsibilities:


Check whether each sentence is supported by its cited sources.


Detect:


Missing citations.


Unsupported claims.


Mis-citations.




Prompt skeleton:
You are a fact-checking assistant.

You are given:
- A draft summary consisting of sentences. Each sentence has citations to article IDs.
- The full text content of those articles.

For each sentence:
1. Decide whether the claim is fully supported, partially supported, or unsupported by the cited sources.
2. If unsupported or only partially supported, explain why.
3. Suggest corrections if possible.

Output a JSON object with:
- "overall_verdict": "accept" or "revise"
- "issues": [ ... list of issues per sentence ... ]

The agent loop uses:


overall_verdict = revise → regenerate summary with feedback.


4. Generation strategies
4.1 Map-reduce summarization (optional)
If context is too large:


Map step


Summarize each article (or article subset) independently with citations.




Reduce step


Combine article-level summaries into a global summary.


Handle cross-article conflicts in this step.




4.2 Direct summarization (default)
For the starter implementation:


Use a single summarization pass over carefully-selected top chunks.


5. Hallucination mitigation
Tactics:


Hard instruction: “Use only the provided content. If you are not sure, say you are not sure.”


Require JSON output with sentence-level sources.


Critic pass verifying support.


Penalize or log cases where critic finds unsupported claims. 


6. Model selection


Primary: reliable general-purpose LLM (e.g., GPT-4 level).


Optional:


Cheaper/faster model for routing and grading.


Higher-quality model for final summary.




Local-first:


During development:


Use local models via Ollama for:


Routing.


Draft summarization.




Swap in API models for final deployment. 




7. JSON output parsing


Use LangChain’s PydanticOutputParser or function calling features.


Strict parsing to:


Enforce required keys.


Validate types.


Reject malformed JSON and retry with a clearer system message.




8. Handling conflicting information
Explicit strategy in prompts:


If two sources give different numbers or claims:


Present both:


“Source A reports X [1], while Source B reports Y [2].”




Avoid arbitrarily deciding what is true unless one is clearly more recent or supported.




This ties back to the educational goal of grounding and avoiding overconfident hallucinations. 

---

### docs/architecture/05_frontend-and-api.md

```markdown
# Frontend and API Architecture

## 1. Frontend goals

- Minimal but functional interface for:
  - Entering news queries.
  - Selecting options (time window, verification on/off, max articles).
  - Displaying:
    - Summary.
    - Source list.
    - Raw article excerpts.
- Rapid to build and demo-friendly.

## 2. Streamlit application

File: `src/news_rag/ui/streamlit_app.py`

### 2.1 Layout

- Sidebar:
  - Text input: “Topic or question about current news”.
  - Select box: time range (`24h`, `7d`, `30d`, `all`).
  - Checkbox: “Enable verification (slower, more accurate)”.
  - Slider: “Max articles” (3–15).
  - Button: “Summarize”.

- Main area:
  - Section: “Summary”
    - Render `summary_text` with sentence-level citations inline.
  - Section: “Sources”
    - Collapsible panels per article:
      - Title + source + published_at.
      - URL.
      - Excerpt used for summarization.
  - Section: “Debug info”
    - Number of search attempts.
    - Search provider used (Tavily or GNews).
    - Total tokens used (optional).

### 2.2 Interaction model

- On “Summarize” click:
  - Frontend sends POST to FastAPI `/summarize`.
  - Displays loading indicator while awaiting response.
  - On success:
    - Render summary and sources.
  - On failure:
    - Render error message from backend.

## 3. API design

File: `src/news_rag/api/server.py`

### 3.1 Endpoints

1. `GET /health`
   - Returns status object:
     - `status: "ok"`
     - `llm_provider`
     - `search_provider`.

2. `POST /summarize`
   - Request:
     ```json
     {
       "query": "What is happening with solid-state batteries?",
       "time_range": "7d",
       "verification": true,
       "max_articles": 10
     }
     ```
   - Response:
     ```json
     {
       "topic": "...",
       "summary_text": "...",
       "sentences": [
         {
           "text": "...",
           "source_ids": ["1", "3"]
         }
       ],
       "sources": [
         {
           "id": "1",
           "title": "...",
           "source": "Reuters",
           "url": "...",
           "published_at": "2025-12-01T12:00:00Z",
           "content": "..."
         }
       ],
       "meta": {
         "search_attempts": 2,
         "search_provider": "tavily",
         "time_range": "7d"
       }
     }
     ```

3. `POST /debug/run-graph`
   - Optional; returns state transitions for debugging during development.

### 3.2 API consumption

- Streamlit app calls `/summarize`.
- External clients can:
  - Build their own UIs.
  - Integrate into workflows (e.g., Slack bots, email digests).

## 4. Cross-origin and security

- If separate frontend:
  - Enable CORS with allowed origins.
- Secrets:
  - API keys stored in environment variables, not in frontend.

## 5. OpenAPI documentation

- FastAPI auto-generates `/docs` and `/openapi.json`.
- `docs/api/openapi.md`:
  - Documents:
    - Request/response schemas.
    - Example calls (curl, Python, JS).


docs/architecture/06_devops-and-observability.md
# DevOps and Observability Architecture

## 1. Deployment targets

Initial phase (course project):
- Single Docker container:
  - Runs FastAPI + Streamlit in one process or side-by-side with `uvicorn` and Streamlit.

Later:
- Containerized microservice:
  - Backend container.
  - Frontend container (if decoupled).

## 2. Dockerization

`docker/Dockerfile`:

- Base: `python:3.11-slim`.
- Install system dependencies.
- Install project via `pyproject.toml` or `requirements.txt`.
- Entrypoint:
  - Launch `uvicorn` for API.
  - Launch Streamlit either:
    - Via separate process supervisor (for simple demo), or
    - Use API only and host Streamlit separately.

`docker/docker-compose.yml`:
- Services:
  - `backend` (FastAPI + agent).
  - `ui` (optional standalone Streamlit).
- Shared network.

## 3. Configuration management

- `.env.example` with:
  - `OPENAI_API_KEY=...`
  - `TAVILY_API_KEY=...`
  - `GNEWS_API_KEY=...` (optional)
  - `NEWS_RAG_MODEL_NAME=...`
  - etc.

- Load via `python-dotenv` or environment directly.

## 4. Logging

- Structured logging:
  - Logger name per module (`news_rag.tools`, `news_rag.core`, etc.).
  - Levels:
    - INFO for normal operation.
    - DEBUG for development (include agent decision traces).
  - Log fields:
    - request_id
    - user query
    - search provider and attempts
    - number of articles and chunks
    - errors.

## 5. Observability with LangSmith (optional)

- Instrument LangChain / LangGraph:
  - Enable tracing:
    - See each agent step (Thought, Action, Observation).
  - Useful for:
    - Debugging infinite loops.
    - Optimizing prompts and tool usage. :contentReference[oaicite:17]{index=17}

## 6. Metrics (lightweight)

- Basic application metrics:
  - Number of `/summarize` calls.
  - Latency histograms (p50, p95).
  - External API call counts (Tavily, GNews).
- Implement via:
  - Simple in-memory counters for class projects.
  - Optional Prometheus/OpenTelemetry for more advanced setups.

## 7. CI/CD

Minimal CI:
- Linting (e.g., `ruff`, `black`).
- Unit tests:
  - `pytest tests/unit`.
- Optional:
  - Integration tests with mocked Tavily responses.

Deployment:
- Build docker image.
- Push to container registry.
- Deploy to:
  - Render / Fly.io / Railway / Heroku-style PaaS, or on-prem VM.

## 8. Failure handling

- External API failure:
  - Log error.
  - Switch to fallback provider.
- LLM failure:
  - Retry once or twice with exponential backoff.
  - Fallback to simpler model or degraded response.
- Agent failure (max steps, unexpected state):
  - Abort with explicit error in response.


docs/architecture/07_testing-and-evaluation.md
# Testing and Evaluation Architecture

## 1. Testing goals

- Ensure retrieval correctness (right sources, no obvious garbage).
- Ensure summarization respects:
  - Citation format.
  - Grounding to sources.
  - Conflict handling.
- Guard against regressions as prompts and tools change.

## 2. Test types

### 2.1 Unit tests

- `tests/unit/test_tavily_tool.py`
  - Mock Tavily responses.
  - Validate:
    - `Article` parsing.
    - Deduplication.
    - Time filtering.

- `tests/unit/test_router.py`
  - Check classification between `news` and `general` queries.

- `tests/unit/test_summarization.py`
  - Provide small hand-crafted article set.
  - Assert:
    - JSON output is valid.
    - Every sentence has at least one source ID.

- `tests/unit/test_verification.py`
  - Provide example with known unsupported claims.
  - Ensure critic flags them.

### 2.2 Integration tests

- `tests/integration/test_end_to_end.py`
  - Run full agent on mocked retrieval layer returning recorded fixtures.
  - Assert:
    - Agent terminates within bounded steps.
    - Reasonable summary shape (length, citations present).

- `tests/integration/test_api.py`
  - Hit `/summarize` with fixed query.
  - Check HTTP status, response structure, and basic invariants.

## 3. Fixtures and recorded data

- Store JSON snapshots of Tavily/GNews responses for a few topics.
- Use those for deterministic tests to avoid live external calls.

## 4. Evaluation of summary quality

Dimensions:

1. **Factual grounding**
   - Manual evaluation:
     - Sample sentences.
     - Check against sources.
2. **Coverage**
   - Does the summary cover major angles present in the sources?
3. **Conciseness**
   - Is the summary appropriately compact (no unnecessary redundancy)?
4. **Conflict articulation**
   - Are major disagreements between sources surfaced?

For educational context, define small rubric for grading projects.

## 5. Load and robustness testing

- Simple script:
  - Repeatedly call `/summarize` with different queries.
  - Monitor:
    - Latency.
    - Rate of external API failures.
- No need for heavy load testing for a class project; aim to demonstrate resilience under modest concurrency.

## 6. Safety checks

- Ensure model does not:
  - Fabricate URLs.
  - Claim insider / confidential information.
- Add prompt-level instructions:
  - “Only use URLs and sources that appear in the provided data.”

## 7. Regression strategy

- When prompts or models change:
  - Re-run test suite.
  - Compare:
    - Summary quality metrics.
    - Citation structure.
- Keep a small “golden” set of queries + expected summaries for regression comparison.


docs/architecture/08_future-work-and-extensions.md
# Future Work and Extensions

## 1. Enhanced agentic behavior

- More sophisticated planning:
  - Multi-stage research: “overview” then “specific angles” (economics, politics, tech).
- Additional tools:
  - Sentiment analysis of coverage.
  - Entity extraction to track people, companies, locations.

## 2. Persistent knowledge

- Build a time-indexed vector store:
  - Archive article embeddings.
  - Allow:
    - Longitudinal questions: “How has coverage of X changed over the last year?”
- Requires:
  - Ingestion pipeline.
  - Background jobs.

## 3. Multi-lingual support

- Detection of query language.
- Search and summarization in the same language.
- Cross-lingual:
  - Fetch sources in multiple languages and summarize in user’s preferred language.

## 4. Delivery channels

- Slack bot:
  - Slash command `/news topic:...`.
- Email digests:
  - Daily summary for subscribed topics.
- Browser extension:
  - Summarize any news article with attribution.

## 5. Advanced verification

- Integrate with fact-checking datasets or APIs:
  - Check claims against structured knowledge where possible. :contentReference[oaicite:18]{index=18}
- Multi-hop reasoning:
  - Decompose complex queries into subclaims and verify each.

## 6. UX improvements

- Interactive summary:
  - Click on a sentence to highlight supporting article segments.
- Timeline view:
  - Show how the story evolved over multiple days.

## 7. Performance and cost optimization

- Dynamic model selection:
  - Use cheaper models for routing and grading.
  - Reserve premium models for final summary.
- Caching and shared context:
  - Share retrieval results across users for hot topics.

## 8. Academic extensions

- Compare:
  - Chain-based RAG vs agentic LangGraph RAG in controlled experiments. :contentReference[oaicite:19]{index=19}
- Add instrumentation for:
  - Measuring hallucination rate with and without verification agent.
- Use as a teaching tool in CS 4200:
  - Students can modify individual components (router, tools, prompts) and observe impact.


That set of files plus the repo layout gives a complete full-stack and agentic RAG architecture for the “AI-Powered News Summarizer with Source Attribution” project.